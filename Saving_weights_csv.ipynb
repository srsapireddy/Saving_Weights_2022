{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install np_utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z24q12kqaWMn",
        "outputId": "6d3aedff-9403-416d-8db0-28ea4c9ab51e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: np_utils in /usr/local/lib/python3.8/dist-packages (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.8/dist-packages (from np_utils) (1.21.6)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQ4ul71hZdXB",
        "outputId": "225e9f94-290a-4e89-e1be-9359363c3455"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 26, 26, 64)        640       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                16010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 53,578\n",
            "Trainable params: 53,578\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "469/469 [==============================] - 5s 4ms/step - loss: 0.8972 - accuracy: 0.7945 - val_loss: 0.2675 - val_accuracy: 0.9290\n",
            "Epoch 2/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.2252 - accuracy: 0.9362 - val_loss: 0.1657 - val_accuracy: 0.9526\n",
            "Epoch 3/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.1583 - accuracy: 0.9545 - val_loss: 0.1257 - val_accuracy: 0.9627\n",
            "Epoch 4/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.1260 - accuracy: 0.9632 - val_loss: 0.1004 - val_accuracy: 0.9720\n",
            "Epoch 5/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.1077 - accuracy: 0.9680 - val_loss: 0.0887 - val_accuracy: 0.9726\n",
            "Epoch 6/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0947 - accuracy: 0.9724 - val_loss: 0.0795 - val_accuracy: 0.9748\n",
            "Epoch 7/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0853 - accuracy: 0.9747 - val_loss: 0.0736 - val_accuracy: 0.9770\n",
            "Epoch 8/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0780 - accuracy: 0.9765 - val_loss: 0.0638 - val_accuracy: 0.9803\n",
            "Epoch 9/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0722 - accuracy: 0.9787 - val_loss: 0.0620 - val_accuracy: 0.9810\n",
            "Epoch 10/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0676 - accuracy: 0.9797 - val_loss: 0.0609 - val_accuracy: 0.9808\n",
            "Epoch 11/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0634 - accuracy: 0.9813 - val_loss: 0.0583 - val_accuracy: 0.9817\n",
            "Epoch 12/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0601 - accuracy: 0.9824 - val_loss: 0.0578 - val_accuracy: 0.9820\n",
            "Epoch 13/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0568 - accuracy: 0.9833 - val_loss: 0.0492 - val_accuracy: 0.9848\n",
            "Epoch 14/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0543 - accuracy: 0.9837 - val_loss: 0.0471 - val_accuracy: 0.9847\n",
            "Epoch 15/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0517 - accuracy: 0.9847 - val_loss: 0.0470 - val_accuracy: 0.9848\n",
            "Epoch 16/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0495 - accuracy: 0.9854 - val_loss: 0.0454 - val_accuracy: 0.9860\n",
            "Epoch 17/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0472 - accuracy: 0.9861 - val_loss: 0.0443 - val_accuracy: 0.9860\n",
            "Epoch 18/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0455 - accuracy: 0.9864 - val_loss: 0.0447 - val_accuracy: 0.9852\n",
            "Epoch 19/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0440 - accuracy: 0.9872 - val_loss: 0.0410 - val_accuracy: 0.9869\n",
            "Epoch 20/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0425 - accuracy: 0.9877 - val_loss: 0.0399 - val_accuracy: 0.9872\n",
            "Epoch 21/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0411 - accuracy: 0.9881 - val_loss: 0.0439 - val_accuracy: 0.9846\n",
            "Epoch 22/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0400 - accuracy: 0.9883 - val_loss: 0.0398 - val_accuracy: 0.9864\n",
            "Epoch 23/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0382 - accuracy: 0.9889 - val_loss: 0.0388 - val_accuracy: 0.9878\n",
            "Epoch 24/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0374 - accuracy: 0.9890 - val_loss: 0.0391 - val_accuracy: 0.9878\n",
            "Epoch 25/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0364 - accuracy: 0.9894 - val_loss: 0.0401 - val_accuracy: 0.9873\n",
            "Epoch 26/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0355 - accuracy: 0.9896 - val_loss: 0.0392 - val_accuracy: 0.9879\n",
            "Epoch 27/50\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0343 - accuracy: 0.9901 - val_loss: 0.0381 - val_accuracy: 0.9878\n",
            "Epoch 28/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0333 - accuracy: 0.9906 - val_loss: 0.0369 - val_accuracy: 0.9877\n",
            "Epoch 29/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0324 - accuracy: 0.9903 - val_loss: 0.0396 - val_accuracy: 0.9872\n",
            "Epoch 30/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0322 - accuracy: 0.9908 - val_loss: 0.0361 - val_accuracy: 0.9883\n",
            "Epoch 31/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0307 - accuracy: 0.9910 - val_loss: 0.0367 - val_accuracy: 0.9879\n",
            "Epoch 32/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0299 - accuracy: 0.9914 - val_loss: 0.0361 - val_accuracy: 0.9884\n",
            "Epoch 33/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0294 - accuracy: 0.9914 - val_loss: 0.0348 - val_accuracy: 0.9886\n",
            "Epoch 34/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0284 - accuracy: 0.9918 - val_loss: 0.0369 - val_accuracy: 0.9880\n",
            "Epoch 35/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0280 - accuracy: 0.9918 - val_loss: 0.0364 - val_accuracy: 0.9878\n",
            "Epoch 36/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0269 - accuracy: 0.9920 - val_loss: 0.0358 - val_accuracy: 0.9885\n",
            "Epoch 37/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0264 - accuracy: 0.9921 - val_loss: 0.0391 - val_accuracy: 0.9880\n",
            "Epoch 38/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0258 - accuracy: 0.9929 - val_loss: 0.0355 - val_accuracy: 0.9883\n",
            "Epoch 39/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0252 - accuracy: 0.9927 - val_loss: 0.0354 - val_accuracy: 0.9885\n",
            "Epoch 40/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0246 - accuracy: 0.9931 - val_loss: 0.0366 - val_accuracy: 0.9880\n",
            "Epoch 41/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0243 - accuracy: 0.9932 - val_loss: 0.0365 - val_accuracy: 0.9883\n",
            "Epoch 42/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0233 - accuracy: 0.9930 - val_loss: 0.0345 - val_accuracy: 0.9885\n",
            "Epoch 43/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0228 - accuracy: 0.9935 - val_loss: 0.0369 - val_accuracy: 0.9881\n",
            "Epoch 44/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0224 - accuracy: 0.9935 - val_loss: 0.0357 - val_accuracy: 0.9891\n",
            "Epoch 45/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0217 - accuracy: 0.9938 - val_loss: 0.0353 - val_accuracy: 0.9882\n",
            "Epoch 46/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0209 - accuracy: 0.9941 - val_loss: 0.0340 - val_accuracy: 0.9892\n",
            "Epoch 47/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0208 - accuracy: 0.9941 - val_loss: 0.0360 - val_accuracy: 0.9889\n",
            "Epoch 48/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0203 - accuracy: 0.9941 - val_loss: 0.0361 - val_accuracy: 0.9891\n",
            "Epoch 49/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0202 - accuracy: 0.9941 - val_loss: 0.0359 - val_accuracy: 0.9881\n",
            "Epoch 50/50\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0188 - accuracy: 0.9946 - val_loss: 0.0346 - val_accuracy: 0.9887\n",
            "Training time: 85.64286661148071\n",
            "\n",
            "Test accuracy: 98.9%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import tensorflow\n",
        "tensorflow.random.set_seed(22)\n",
        "\n",
        "# load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# from sparse label to categorical\n",
        "num_labels = len(np.unique(y_train))\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# reshape and normalize input images\n",
        "image_size = x_train.shape[1]\n",
        "x_train = np.reshape(x_train,[-1, image_size, image_size, 1])\n",
        "x_test = np.reshape(x_test,[-1, image_size, image_size, 1])\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# network parameters\n",
        "input_shape = (image_size, image_size, 1)\n",
        "batch_size = 128\n",
        "kernel_size = 3\n",
        "filters = 64\n",
        "dropout = 0.3\n",
        "\n",
        "# use functional API to build cnn layers\n",
        "inputs = Input(shape=input_shape)\n",
        "\n",
        "y = Conv2D(filters=filters,\n",
        "           kernel_size=kernel_size,\n",
        "           activation='relu')(inputs)\n",
        "\n",
        "y = MaxPooling2D()(y)\n",
        "\n",
        "y = Conv2D(filters=filters,\n",
        "           kernel_size=kernel_size,\n",
        "           activation='relu')(y)\n",
        "\n",
        "y = MaxPooling2D()(y)\n",
        "# y = Conv2D(filters=filters,\n",
        "#            kernel_size=kernel_size,\n",
        "#            activation='relu')(y)\n",
        "# image to vector before connecting to dense layer\n",
        "y = Flatten()(y)\n",
        "# dropout regularization\n",
        "#y = Dropout(dropout)(y)\n",
        "outputs = Dense(num_labels, activation='softmax')(y)\n",
        "\n",
        "\n",
        "\n",
        "# build the model by supplying inputs/outputs\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "# network model in text\n",
        "model.summary()\n",
        "# Retrieve the config\n",
        "\n",
        "# classifier loss, Adam optimizer, classifier accuracy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# classifier loss, Adam optimizer, classifier accuracy\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.0001),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "import time\n",
        "t0 = time.time()\n",
        "# train the model with input images and labels\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          validation_data=(x_test, y_test),\n",
        "          epochs=50,\n",
        "          batch_size=batch_size)\n",
        "print(\"Training time:\", time.time()-t0)\n",
        "\n",
        "# model accuracy on test dataset\n",
        "score = model.evaluate(x_test,\n",
        "                       y_test,\n",
        "                       batch_size=batch_size,\n",
        "                       verbose=0)\n",
        "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * score[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Method_1 - Not all weights are printed"
      ],
      "metadata": {
        "id": "sizli6KV2T3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weight = model.get_weights()\n",
        "np.savetxt('weight_method_1.csv' , weight , fmt='%s', delimiter=',')"
      ],
      "metadata": {
        "id": "fVyLDECsbpWx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca462715-53dd-467f-e1cd-ee501c272733"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py:1378: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X = np.asarray(X)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Method_2 - Printing weights to console"
      ],
      "metadata": {
        "id": "Lz4L5Vhk2iVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in model.layers:\n",
        "        print(\"------\")\n",
        "        print(i, \"\\n\", i.input_shape, \"\\n\", i.output_shape, \"\\n\", i.get_weights())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZahQ8kmZg5uL",
        "outputId": "5a2b8767-a97b-4cca-c693-031493a7506f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------\n",
            "<keras.engine.input_layer.InputLayer object at 0x7feb1c349c40> \n",
            " [(None, 28, 28, 1)] \n",
            " [(None, 28, 28, 1)] \n",
            " []\n",
            "------\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7feb1189aaf0> \n",
            " (None, 28, 28, 1) \n",
            " (None, 26, 26, 64) \n",
            " [array([[[[-1.80219978e-01,  1.58700526e-01,  1.40067384e-01,\n",
            "           1.01181969e-01,  2.71935239e-02,  1.43903732e-01,\n",
            "           1.46139145e-01,  2.02964574e-01,  5.35398610e-02,\n",
            "           1.75139830e-01,  1.84737548e-01,  2.05435917e-01,\n",
            "           1.78475052e-01,  1.41623184e-01,  1.22648790e-01,\n",
            "          -3.28015499e-02,  2.26218570e-02,  1.56232137e-02,\n",
            "          -2.25300297e-01,  3.93555835e-02,  1.23589724e-01,\n",
            "           2.95741912e-02,  1.34825945e-01, -1.12767316e-01,\n",
            "           1.93588540e-01,  9.14105922e-02,  2.10980967e-01,\n",
            "           2.44016899e-03,  1.30973250e-01,  3.08532625e-01,\n",
            "           2.49243796e-01,  4.91356030e-02,  2.10800886e-01,\n",
            "           9.82838124e-02, -2.32862309e-01,  1.05640151e-01,\n",
            "           1.28863111e-01,  4.14711721e-02, -6.35426119e-02,\n",
            "          -2.69169509e-02,  1.45494118e-01,  1.75936207e-01,\n",
            "           6.26810044e-02,  1.53128579e-01, -2.12632492e-01,\n",
            "           8.80916864e-02,  1.66982010e-01,  1.20964199e-01,\n",
            "           2.42551923e-01,  1.67123064e-01, -9.96137261e-02,\n",
            "          -7.32066780e-02, -9.41924602e-02, -9.11591668e-03,\n",
            "          -3.54200393e-01, -2.32694149e-02, -1.93761915e-01,\n",
            "           8.28594714e-03, -3.32546718e-02,  7.64708668e-02,\n",
            "          -5.91178052e-02,  1.37015581e-01,  2.64929265e-01,\n",
            "           1.33913115e-01]],\n",
            "\n",
            "        [[-2.33336568e-01,  9.90212411e-02,  1.32687613e-01,\n",
            "           1.50890112e-01, -6.11798577e-02,  3.08020771e-01,\n",
            "           1.70209222e-02,  8.77180621e-02,  2.13742882e-01,\n",
            "           2.15274230e-01,  1.58826679e-01,  1.17098920e-01,\n",
            "           5.85453063e-02,  1.40305564e-01,  2.25652680e-01,\n",
            "           1.44081861e-01, -9.44648907e-02, -2.00986378e-02,\n",
            "          -3.58187735e-01,  2.67722947e-03,  3.07944208e-01,\n",
            "           1.77321583e-01,  1.25518888e-01, -2.75993168e-01,\n",
            "           1.05616212e-01,  1.43314347e-01,  2.03354836e-01,\n",
            "           1.68326467e-01,  1.04862198e-01,  1.86646163e-01,\n",
            "           2.97123134e-01,  8.79677534e-02,  1.65122345e-01,\n",
            "           9.39749777e-02,  1.55590817e-01,  1.40820786e-01,\n",
            "           1.99446231e-01,  6.93242848e-02,  2.28392333e-02,\n",
            "           9.80457813e-02,  1.48167580e-01,  1.05373025e-01,\n",
            "          -1.45463785e-02,  9.75244418e-02, -1.22392789e-01,\n",
            "           1.59717843e-01,  5.22392690e-02,  1.17930427e-01,\n",
            "           1.71645299e-01,  2.17436776e-01, -1.74070835e-01,\n",
            "           1.37183322e-02,  1.60199806e-01,  1.54373050e-01,\n",
            "          -3.66312936e-02, -5.60534298e-02, -1.94134623e-01,\n",
            "           1.43153608e-01,  1.03190318e-01,  2.27143407e-01,\n",
            "           8.46959930e-03,  2.60278024e-02,  1.30068615e-01,\n",
            "           1.23313010e-01]],\n",
            "\n",
            "        [[-1.69713005e-01,  1.16191581e-01,  2.12368846e-01,\n",
            "           5.44673875e-02, -3.68547320e-01,  1.74138635e-01,\n",
            "           1.27050906e-01, -1.27197146e-01,  1.90482929e-01,\n",
            "          -7.95201436e-02,  3.96686867e-02, -5.37552312e-02,\n",
            "           1.31218642e-01,  6.26763105e-02,  1.44481987e-01,\n",
            "           2.99120516e-01, -4.46317233e-02,  2.55097225e-02,\n",
            "          -1.97229862e-01,  1.11390285e-01,  2.02504441e-01,\n",
            "           2.16631740e-01, -2.06805747e-02, -2.19276235e-01,\n",
            "          -2.71651924e-01,  1.75793484e-01,  1.96087837e-01,\n",
            "           1.33008748e-01,  5.12582324e-02, -6.10566922e-02,\n",
            "           8.11385736e-02, -2.14813873e-01, -5.50644584e-02,\n",
            "           8.72996524e-02,  1.29245132e-01, -1.78586438e-01,\n",
            "           1.40599921e-01,  1.66635796e-01,  1.76058382e-01,\n",
            "           6.52206838e-02,  1.75513461e-01,  1.77308440e-01,\n",
            "           2.18151063e-01,  1.95736840e-01,  1.32889107e-01,\n",
            "           1.07460514e-01, -3.15299690e-01,  1.92743689e-01,\n",
            "           2.30661467e-01,  1.55268565e-01, -1.49245664e-01,\n",
            "           2.59673893e-01,  1.49900079e-01, -2.55297255e-02,\n",
            "           2.57376134e-01, -4.65911590e-02, -1.62637264e-01,\n",
            "          -1.42137080e-01,  2.62710333e-01,  2.24443719e-01,\n",
            "           1.74238741e-01, -8.31777826e-02, -2.90893521e-02,\n",
            "           2.44906992e-01]]],\n",
            "\n",
            "\n",
            "       [[[-5.67955784e-02, -6.72248825e-02,  1.04345322e-01,\n",
            "           2.15163499e-01,  1.12894379e-01,  1.81158215e-01,\n",
            "           1.74174577e-01,  1.91517219e-01,  8.99750292e-02,\n",
            "          -3.97419790e-03,  1.24774069e-01,  1.25875846e-01,\n",
            "           5.84356189e-02,  3.49197350e-02,  1.21061496e-01,\n",
            "           1.49456471e-01, -2.30426248e-02,  2.70061195e-02,\n",
            "           1.07494056e-01,  1.50888506e-02,  5.97615279e-02,\n",
            "           9.13758799e-02,  2.47247607e-01,  1.15823112e-01,\n",
            "           6.36764616e-02,  2.35486820e-01,  1.93038017e-01,\n",
            "           1.09592184e-01,  1.72572806e-01,  7.29419515e-02,\n",
            "          -2.21013166e-02,  2.68130153e-01,  1.60743803e-01,\n",
            "           1.55581474e-01, -2.67101049e-01,  1.29272893e-01,\n",
            "           4.02753539e-02,  1.45423114e-02, -6.28192052e-02,\n",
            "           7.04824626e-02, -8.24471563e-02,  1.92948401e-01,\n",
            "           8.11008364e-02,  1.66829273e-01, -2.05445051e-01,\n",
            "           1.29264534e-01,  2.43026108e-01,  6.69613630e-02,\n",
            "           2.30340973e-01, -1.51025549e-01,  1.51986286e-01,\n",
            "           1.53740585e-01,  2.13415116e-01,  2.14495972e-01,\n",
            "          -2.09951892e-01, -4.74175662e-02,  1.61510985e-02,\n",
            "           2.16524348e-01,  2.34101370e-01, -6.20861677e-03,\n",
            "           7.47865736e-02,  2.53061682e-01,  2.36806884e-01,\n",
            "           1.21656179e-01]],\n",
            "\n",
            "        [[ 4.71547507e-02,  4.62305173e-02,  1.25200814e-03,\n",
            "           1.46538720e-01,  3.61965112e-02,  2.00700432e-01,\n",
            "           1.55002661e-02, -8.23795795e-02, -8.55234079e-03,\n",
            "           1.75047964e-01,  2.38798425e-01,  1.59480602e-01,\n",
            "           2.62168735e-01,  1.35935083e-01,  1.30469590e-01,\n",
            "           2.47072533e-01,  2.34916791e-01,  2.28984714e-01,\n",
            "           9.55880508e-02,  5.68943396e-02,  3.26602340e-01,\n",
            "           3.18655610e-01,  2.84209967e-01, -1.16836083e-04,\n",
            "           1.46328405e-01,  1.61555722e-01,  7.25653470e-02,\n",
            "           2.12813392e-01,  2.14125633e-01,  1.60698041e-01,\n",
            "           1.48885772e-01, -7.35388398e-02,  2.49429911e-01,\n",
            "           1.21330433e-01,  1.49217015e-02,  6.24205880e-02,\n",
            "           2.13672459e-01,  2.56270636e-02,  9.59365070e-02,\n",
            "           5.42919077e-02, -4.53588646e-03,  6.74398169e-02,\n",
            "           1.59900814e-01,  3.34626496e-01,  1.38143107e-01,\n",
            "           2.03319743e-01, -2.79060937e-03,  1.89322904e-01,\n",
            "           2.38633186e-01, -1.54493824e-02, -6.84658289e-02,\n",
            "           1.90576464e-01,  1.20256975e-01,  2.61120617e-01,\n",
            "           4.31329608e-02, -4.13302220e-02,  5.47013991e-02,\n",
            "           8.96383077e-03,  1.68800861e-01,  9.72844437e-02,\n",
            "           7.02145770e-02,  2.65347391e-01, -5.30082695e-02,\n",
            "           6.50488064e-02]],\n",
            "\n",
            "        [[ 1.08634485e-02,  9.04347599e-02, -6.76531417e-05,\n",
            "          -2.41197809e-03, -7.41516948e-02,  2.62178015e-04,\n",
            "           1.25464454e-01, -2.06822440e-01,  1.12446457e-01,\n",
            "           1.11614957e-01,  1.96072266e-01,  1.83299914e-01,\n",
            "           1.13375187e-01,  1.89594612e-01,  3.64820920e-02,\n",
            "           1.86352208e-01,  1.83560893e-01,  2.33730510e-01,\n",
            "           1.06712459e-02,  1.16380677e-02,  7.24004656e-02,\n",
            "           1.37459174e-01, -1.20725483e-02, -6.24544770e-02,\n",
            "          -2.99270391e-01,  4.28133272e-02,  1.11047491e-01,\n",
            "           1.04848437e-01,  2.02220187e-01,  1.12297721e-01,\n",
            "           1.03239909e-01, -2.28934243e-01,  1.14037514e-01,\n",
            "           1.12113349e-01,  1.69018939e-01, -2.34735221e-01,\n",
            "           2.71271467e-01,  1.44114196e-01,  1.13131024e-01,\n",
            "           1.16768040e-01,  1.66221753e-01,  1.98402941e-01,\n",
            "           1.84573635e-01,  4.60034534e-02,  8.74609947e-02,\n",
            "           2.50260323e-01, -2.09144861e-01,  4.24175225e-02,\n",
            "          -8.12567249e-02,  2.01707780e-01, -3.09402913e-01,\n",
            "           1.82940587e-01,  1.94241196e-01,  1.94596976e-01,\n",
            "           1.70553997e-01, -2.68226117e-03,  4.25227396e-02,\n",
            "          -3.29891533e-01, -1.23680029e-02,  7.13835284e-03,\n",
            "           1.97156802e-01,  9.97697711e-02, -2.91507095e-01,\n",
            "           7.66017707e-03]]],\n",
            "\n",
            "\n",
            "       [[[ 2.41437986e-01,  4.66492586e-02, -2.45399877e-01,\n",
            "           2.12998226e-01,  2.15795934e-01,  3.21387090e-02,\n",
            "           2.13740498e-01, -8.23222697e-02, -3.12327236e-01,\n",
            "          -1.71717718e-01, -4.16590907e-02, -1.05970569e-01,\n",
            "           8.30431432e-02, -2.54475653e-01, -4.79260720e-02,\n",
            "           6.74378425e-02,  1.66761979e-01,  1.34203523e-01,\n",
            "           1.19641893e-01,  2.44146362e-01, -8.81534293e-02,\n",
            "           1.15797251e-01,  1.56677976e-01,  1.66086018e-01,\n",
            "           1.91160083e-01,  1.37883902e-01,  3.24451737e-02,\n",
            "           1.06361091e-01,  2.36817211e-01, -5.47291860e-02,\n",
            "          -1.56101122e-01,  2.12231502e-01,  6.44213930e-02,\n",
            "           1.65037885e-01, -2.11354882e-01,  2.32654154e-01,\n",
            "          -1.34959370e-01,  1.93915918e-01,  1.58579499e-01,\n",
            "           2.28524297e-01, -2.96258926e-01, -9.90710258e-02,\n",
            "           2.11980164e-01,  1.39241859e-01, -1.29441796e-02,\n",
            "           4.39331941e-02,  9.69454870e-02,  1.85542911e-01,\n",
            "           4.55652364e-02, -2.36680657e-01,  3.10885936e-01,\n",
            "           2.43769988e-01,  1.18662164e-01,  2.10703433e-01,\n",
            "          -1.42292634e-01, -1.43653676e-02,  2.15471774e-01,\n",
            "           2.55198568e-01, -2.81566381e-02, -1.01361051e-01,\n",
            "           2.17086822e-01,  4.07636613e-02,  1.29267752e-01,\n",
            "          -2.26532966e-01]],\n",
            "\n",
            "        [[ 1.42608806e-01,  1.49967656e-01, -1.85398862e-01,\n",
            "           1.61045790e-01,  2.69271106e-01,  1.78506435e-03,\n",
            "           2.14177534e-01, -3.53382409e-01, -2.06702381e-01,\n",
            "           5.17334230e-02,  1.86213888e-02,  1.05543673e-01,\n",
            "           1.44959703e-01, -2.65325993e-01,  1.81946725e-01,\n",
            "           1.29293859e-01,  2.52162397e-01,  2.22819790e-01,\n",
            "           2.49325648e-01,  1.77748233e-01,  6.39850721e-02,\n",
            "           2.40282521e-01,  1.98456332e-01,  2.68903375e-01,\n",
            "           9.84087959e-02, -1.67480670e-03,  2.40456685e-01,\n",
            "           1.22952543e-01,  1.47455037e-01,  9.73149016e-02,\n",
            "           8.41267407e-02,  3.64718214e-02,  7.49349594e-03,\n",
            "           1.90366030e-01, -1.53767085e-02,  1.11797731e-02,\n",
            "           1.97623372e-02,  5.92520386e-02,  2.27494329e-01,\n",
            "           2.87260354e-01, -1.73800394e-01, -8.01311582e-02,\n",
            "           1.74559038e-02,  2.37536486e-02,  2.59562343e-01,\n",
            "           1.91488534e-01,  2.28650317e-01,  2.36007012e-02,\n",
            "          -1.29010201e-01, -2.28014305e-01,  1.97612360e-01,\n",
            "           1.35393798e-01,  1.90604478e-02,  2.02778637e-01,\n",
            "           7.63042495e-02, -3.97079773e-02,  1.24221303e-01,\n",
            "           8.30729529e-02, -1.76672861e-01, -3.14273298e-01,\n",
            "           1.45183668e-01,  2.82522202e-01, -1.51228741e-01,\n",
            "          -2.23302469e-01]],\n",
            "\n",
            "        [[ 1.93457484e-01,  2.12853566e-01, -3.81113142e-02,\n",
            "           7.77738467e-02,  1.32669941e-01,  6.22146949e-02,\n",
            "           6.22410178e-02, -1.06312543e-01, -2.76951061e-04,\n",
            "           1.85643941e-01,  2.57004559e-01,  3.18957001e-01,\n",
            "           7.15248808e-02, -1.23203188e-01,  9.32059288e-02,\n",
            "          -1.16260476e-01,  2.62371868e-01,  1.40024677e-01,\n",
            "           1.74317002e-01,  2.13878036e-01,  1.11037605e-01,\n",
            "          -3.80887352e-02, -5.67865148e-02,  1.14801079e-01,\n",
            "          -2.07027897e-01,  4.39008698e-02,  1.45772427e-01,\n",
            "           1.03343137e-01,  1.40755087e-01,  1.32163242e-01,\n",
            "           1.93627626e-01, -6.59971312e-02,  1.10888146e-01,\n",
            "           1.36839420e-01,  2.34785855e-01, -2.60109246e-01,\n",
            "           1.97158337e-01,  1.31688580e-01,  1.71723574e-01,\n",
            "           1.86451301e-01, -7.16680884e-02, -1.76749766e-01,\n",
            "           1.93776060e-02, -2.40855455e-01,  1.92118078e-01,\n",
            "           1.54583991e-01, -6.27094358e-02,  1.76986411e-01,\n",
            "          -3.12936455e-01,  3.70095600e-04,  6.98577091e-02,\n",
            "          -2.26919558e-02, -5.00587523e-02,  2.36965582e-01,\n",
            "           1.04948528e-01, -2.22346112e-02,  1.43359259e-01,\n",
            "          -2.40913942e-01, -2.46764794e-01, -2.31078818e-01,\n",
            "           2.97610350e-02,  1.76780462e-01, -2.30185226e-01,\n",
            "          -2.32602879e-01]]]], dtype=float32), array([ 2.7579015e-02, -9.0492226e-04,  2.6909125e-03, -5.0127559e-04,\n",
            "       -3.2951514e-04, -4.5799866e-04, -3.5236066e-04,  1.3128929e-01,\n",
            "       -1.9565705e-04, -2.6652031e-04, -6.9130247e-04, -7.1552926e-04,\n",
            "       -7.9166231e-04,  9.5662102e-03, -6.0489954e-04, -9.7003824e-04,\n",
            "       -6.1431911e-04, -1.3115333e-03,  3.5530217e-02, -8.1362744e-04,\n",
            "       -1.9762841e-04, -6.6808733e-04, -1.2522562e-04,  2.3512451e-02,\n",
            "       -4.7935903e-04, -4.0557384e-04,  5.1983906e-04, -6.6177809e-04,\n",
            "       -1.7324449e-04, -3.1724185e-04, -2.5789553e-04, -7.2560873e-04,\n",
            "       -6.5257150e-04, -4.5674715e-05,  7.9755289e-03, -4.7709668e-04,\n",
            "       -7.4581825e-04, -4.0165437e-04, -1.4673680e-04, -2.4982524e-04,\n",
            "        1.7155310e-02,  1.0167102e-02, -6.4803433e-04,  7.5007700e-03,\n",
            "        3.1274057e-04, -2.6079625e-04, -5.4050889e-04, -2.1962928e-04,\n",
            "        9.3075221e-05, -7.5800155e-05,  7.3483266e-02, -4.4254001e-04,\n",
            "       -5.6831038e-04, -4.6574170e-04,  3.2330688e-02,  0.0000000e+00,\n",
            "       -2.5714975e-04, -4.9193710e-04, -3.6422040e-05,  2.4988553e-02,\n",
            "       -7.3343440e-04, -7.5252855e-04,  1.2371159e-04,  1.6184900e-02],\n",
            "      dtype=float32)]\n",
            "------\n",
            "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7feaf30574f0> \n",
            " (None, 26, 26, 64) \n",
            " (None, 13, 13, 64) \n",
            " []\n",
            "------\n",
            "<keras.layers.convolutional.conv2d.Conv2D object at 0x7feaf3057760> \n",
            " (None, 13, 13, 64) \n",
            " (None, 11, 11, 64) \n",
            " [array([[[[-4.62988131e-02,  6.76881149e-02,  9.28753689e-02, ...,\n",
            "          -1.21899702e-01,  1.25331044e-01, -9.27022621e-02],\n",
            "         [ 4.92228381e-02,  4.50598225e-02, -3.53076011e-02, ...,\n",
            "           1.06864050e-01,  7.80606992e-04,  7.33602233e-03],\n",
            "         [ 1.35002032e-01,  1.10959888e-01,  7.65445009e-02, ...,\n",
            "          -4.47093397e-02, -1.45731807e-01,  8.61852765e-02],\n",
            "         ...,\n",
            "         [ 6.21533804e-02,  1.28735662e-01,  7.14632496e-02, ...,\n",
            "           1.08237922e-01,  1.74665414e-02, -1.26295928e-02],\n",
            "         [ 7.65080899e-02,  7.00872391e-02, -6.88021109e-02, ...,\n",
            "           1.56516612e-01, -9.40717310e-02, -9.17940363e-02],\n",
            "         [ 9.37809721e-02,  7.30138272e-02,  9.25631151e-02, ...,\n",
            "          -1.57145504e-02, -1.26841843e-01, -8.48988220e-02]],\n",
            "\n",
            "        [[-5.40640317e-02,  1.85694825e-02,  3.03575527e-02, ...,\n",
            "          -6.91024447e-03,  6.05490915e-02, -8.04714188e-02],\n",
            "         [ 3.42894197e-02,  8.24793801e-02,  1.27483699e-02, ...,\n",
            "           9.85080283e-03, -2.70297267e-02,  7.83169568e-02],\n",
            "         [ 4.05060463e-02,  2.83334367e-02, -2.59899180e-02, ...,\n",
            "           1.19342841e-02, -9.82440189e-02, -9.41456780e-02],\n",
            "         ...,\n",
            "         [ 2.51442082e-02,  7.88245127e-02,  6.96822181e-02, ...,\n",
            "          -8.32520127e-02, -1.17919236e-01,  8.55860263e-02],\n",
            "         [ 2.50012061e-04,  8.71265903e-02, -8.61643180e-02, ...,\n",
            "           9.01164338e-02, -9.29088965e-02,  5.97395264e-02],\n",
            "         [ 1.67240724e-01,  4.23641913e-02, -5.25318310e-02, ...,\n",
            "          -3.22976001e-02,  2.27698069e-02, -1.02000713e-01]],\n",
            "\n",
            "        [[-4.32428755e-02,  1.06688060e-01, -8.29598680e-02, ...,\n",
            "          -1.01369828e-01, -4.83311191e-02, -4.44990359e-02],\n",
            "         [ 4.09853347e-02, -1.23058381e-02, -1.67948864e-02, ...,\n",
            "           6.94754720e-02, -5.40348254e-02, -6.12775721e-02],\n",
            "         [ 2.07278341e-01,  2.99258698e-02, -5.35707176e-02, ...,\n",
            "           1.21891610e-02, -6.88943341e-02, -4.17549349e-02],\n",
            "         ...,\n",
            "         [-3.64972837e-03,  9.33221206e-02, -2.09836755e-02, ...,\n",
            "          -7.20884502e-02, -1.21240228e-01, -7.35716298e-02],\n",
            "         [ 1.29269555e-01,  9.82372612e-02,  1.11518865e-02, ...,\n",
            "           7.97727928e-02, -5.42171001e-02,  1.81022834e-03],\n",
            "         [ 2.57670641e-01,  4.90687713e-02, -2.91161090e-02, ...,\n",
            "           1.12956069e-01, -1.78167950e-02, -7.69142061e-04]]],\n",
            "\n",
            "\n",
            "       [[[-1.04729742e-01, -1.17387809e-01, -6.31602705e-02, ...,\n",
            "          -1.17753573e-01,  6.21509515e-02, -1.22065730e-01],\n",
            "         [ 4.45647575e-02,  4.02145982e-02,  4.51364703e-02, ...,\n",
            "           4.62838449e-02,  6.56967387e-02,  6.26123101e-02],\n",
            "         [ 2.28792196e-03,  4.41454984e-02,  1.51414573e-01, ...,\n",
            "          -2.62943488e-02,  2.58304141e-02,  1.15487568e-01],\n",
            "         ...,\n",
            "         [-1.05942473e-01, -6.99966308e-03,  2.20254157e-02, ...,\n",
            "           1.23925723e-01,  1.13884605e-01, -8.20749849e-02],\n",
            "         [-7.29968473e-02, -1.38473778e-03, -1.59189239e-01, ...,\n",
            "           7.16374218e-02,  3.51641723e-03, -1.55301750e-01],\n",
            "         [ 6.53871000e-02,  9.31198448e-02,  7.33385533e-02, ...,\n",
            "          -1.33050248e-01, -1.13832653e-01,  3.22759114e-02]],\n",
            "\n",
            "        [[ 9.01600569e-02,  5.83893768e-02, -1.30539644e-04, ...,\n",
            "           6.35074526e-02,  8.49051494e-03, -1.00115165e-01],\n",
            "         [-1.46917822e-02,  1.36578712e-03,  1.18226580e-01, ...,\n",
            "           3.65195796e-02,  3.99433747e-02,  7.93409720e-02],\n",
            "         [ 6.74390644e-02,  3.49176452e-02,  7.49449432e-03, ...,\n",
            "          -2.00881556e-01, -1.53415903e-01, -2.96947919e-02],\n",
            "         ...,\n",
            "         [-1.13513730e-01,  7.61408806e-02,  8.63689929e-02, ...,\n",
            "          -1.03910780e-02, -1.88887417e-02,  7.54736289e-02],\n",
            "         [-2.14454532e-02,  1.01837076e-01,  5.88037595e-02, ...,\n",
            "           7.44283497e-02, -3.48283350e-02, -6.39690384e-02],\n",
            "         [ 1.11972846e-01,  4.19872217e-02, -1.31352872e-01, ...,\n",
            "          -1.33967221e-01, -1.81440830e-01, -1.91926017e-01]],\n",
            "\n",
            "        [[ 1.47501945e-01, -9.65684801e-02, -1.27427736e-02, ...,\n",
            "           3.36909071e-02,  2.71775499e-02, -1.32462895e-03],\n",
            "         [-1.09235890e-01,  2.03284789e-02,  3.26590687e-02, ...,\n",
            "          -1.25517715e-02, -7.28209391e-02,  1.52140679e-02],\n",
            "         [ 8.58198851e-02,  1.37560472e-01, -1.45717397e-01, ...,\n",
            "           2.61728186e-02, -6.32743761e-02, -2.05817908e-01],\n",
            "         ...,\n",
            "         [-1.07066669e-01, -1.19420335e-01,  8.02787766e-02, ...,\n",
            "          -6.81335703e-02, -1.84753835e-02, -6.79954216e-02],\n",
            "         [-3.75652649e-02,  1.01109661e-01,  6.86649159e-02, ...,\n",
            "          -9.47043598e-02, -6.09520003e-02,  8.10989216e-02],\n",
            "         [ 1.83021687e-02,  1.12296656e-01, -1.02039509e-01, ...,\n",
            "           6.37155771e-02, -4.19938341e-02, -2.86847502e-01]]],\n",
            "\n",
            "\n",
            "       [[[ 9.15577784e-02, -6.43624291e-02,  1.74570791e-02, ...,\n",
            "          -2.10206985e-01, -1.33912712e-01,  7.89359864e-03],\n",
            "         [-4.67269123e-02, -1.33970127e-01, -6.35647178e-02, ...,\n",
            "           9.18862969e-02,  4.40979041e-02,  5.32937050e-02],\n",
            "         [-2.05566287e-01,  3.79023477e-02, -4.84524183e-02, ...,\n",
            "          -5.10180965e-02,  1.21094771e-01,  3.73824239e-02],\n",
            "         ...,\n",
            "         [ 2.76684240e-02, -1.64023146e-01,  6.40436495e-03, ...,\n",
            "           5.73666357e-02, -1.91333853e-02, -1.00753158e-01],\n",
            "         [ 1.46115501e-03, -1.70714706e-02, -8.86065364e-02, ...,\n",
            "           5.47773167e-02,  7.74008455e-04, -9.01957005e-02],\n",
            "         [-6.20779544e-02,  7.87843987e-02, -1.47086810e-02, ...,\n",
            "          -1.45907223e-01,  9.00561810e-02, -4.85133938e-02]],\n",
            "\n",
            "        [[ 1.11463815e-01,  8.80966801e-03, -1.26245052e-01, ...,\n",
            "           4.10281308e-02, -1.61500834e-03, -1.22201182e-01],\n",
            "         [ 6.29419684e-02, -9.76767391e-02,  9.05750412e-03, ...,\n",
            "          -3.71849127e-02,  4.44058180e-02,  6.43774942e-02],\n",
            "         [-1.80530250e-01,  1.13174058e-01,  3.93571220e-02, ...,\n",
            "          -9.32686850e-02,  1.65712480e-02, -5.39930016e-02],\n",
            "         ...,\n",
            "         [ 7.72524327e-02, -1.69565961e-01,  1.21420272e-01, ...,\n",
            "          -1.24196131e-02,  7.91601017e-02, -3.68755460e-02],\n",
            "         [-6.92243576e-02, -4.47099321e-02, -6.94352090e-02, ...,\n",
            "           4.80817109e-02,  7.68477321e-02,  2.77503971e-02],\n",
            "         [-1.19189762e-01,  8.75061378e-02, -1.22430310e-01, ...,\n",
            "          -2.57869177e-02,  5.91620745e-04, -1.76392287e-01]],\n",
            "\n",
            "        [[ 1.80918917e-01,  1.04919106e-01, -4.79856357e-02, ...,\n",
            "           7.94035941e-02,  8.15488696e-02, -3.44011076e-02],\n",
            "         [ 8.78809765e-02, -7.47680143e-02, -1.48815308e-02, ...,\n",
            "           6.31936491e-02, -6.10420015e-03, -8.56984966e-03],\n",
            "         [-1.20278366e-01, -2.95405705e-02, -8.46443474e-02, ...,\n",
            "          -1.93333812e-02,  7.45181590e-02, -1.90239459e-01],\n",
            "         ...,\n",
            "         [ 1.13746829e-01, -1.13897651e-01, -3.58531028e-02, ...,\n",
            "          -4.79416884e-02,  5.15359156e-02,  8.38106051e-02],\n",
            "         [-1.32858410e-01,  5.17521724e-02,  6.35110065e-02, ...,\n",
            "          -1.37122460e-02,  2.24773865e-02, -5.12868837e-02],\n",
            "         [-1.34776622e-01, -7.98704401e-02, -2.93752030e-02, ...,\n",
            "          -1.02140062e-01,  9.67107862e-02, -1.47820249e-01]]]],\n",
            "      dtype=float32), array([ 2.2797946e-02,  5.8864392e-02, -9.9906800e-03, -1.2433808e-02,\n",
            "        7.4994299e-03, -9.9156471e-03,  6.5891296e-03,  1.2420837e-03,\n",
            "       -2.2265924e-02, -2.7427266e-03, -4.3434296e-02,  1.0010960e-02,\n",
            "       -4.5686602e-03, -2.8213199e-02,  1.3784314e-02, -1.4258644e-02,\n",
            "       -1.7498489e-02,  2.1850159e-02, -2.4342956e-02,  2.7442690e-02,\n",
            "        2.2366820e-03, -4.1881584e-02,  1.1467176e-02, -4.4291079e-02,\n",
            "       -2.4756685e-02, -4.3154720e-02,  5.7330023e-02, -7.3299198e-03,\n",
            "        2.4149302e-02, -6.8221064e-03, -8.3445832e-03,  9.3509527e-03,\n",
            "        1.9896561e-03,  3.0831769e-02,  3.2498542e-02, -1.1179218e-02,\n",
            "        2.3135175e-03, -3.7492387e-02, -3.0739531e-02, -2.1021683e-03,\n",
            "        4.7082186e-02, -5.6747109e-02, -2.6764479e-03, -3.2780565e-02,\n",
            "        4.3695126e-02, -8.1338892e-03,  1.4215098e-02, -9.9663201e-05,\n",
            "       -2.1419739e-02, -2.1655018e-02,  2.9913418e-02,  1.3269549e-02,\n",
            "       -3.4063470e-02, -1.4022346e-02, -1.1784225e-02, -3.3615287e-02,\n",
            "        1.6228458e-02, -2.6682414e-02,  1.3661160e-02, -1.5453688e-02,\n",
            "       -2.1701114e-02,  4.6950553e-02, -5.4459227e-03, -1.4979638e-02],\n",
            "      dtype=float32)]\n",
            "------\n",
            "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x7feaf30573d0> \n",
            " (None, 11, 11, 64) \n",
            " (None, 5, 5, 64) \n",
            " []\n",
            "------\n",
            "<keras.layers.reshaping.flatten.Flatten object at 0x7feaf3057e50> \n",
            " (None, 5, 5, 64) \n",
            " (None, 1600) \n",
            " []\n",
            "------\n",
            "<keras.layers.core.dense.Dense object at 0x7feae03d21f0> \n",
            " (None, 1600) \n",
            " (None, 10) \n",
            " [array([[ 0.01788498, -0.02220453, -0.00915296, ...,  0.0213994 ,\n",
            "        -0.00546848,  0.08501409],\n",
            "       [ 0.03215456, -0.02283707,  0.1321574 , ...,  0.0349009 ,\n",
            "        -0.08768102, -0.00716734],\n",
            "       [ 0.00962854,  0.05009099, -0.03418868, ..., -0.02562197,\n",
            "         0.04913739,  0.02464151],\n",
            "       ...,\n",
            "       [-0.01598315, -0.07781906, -0.02605657, ...,  0.01016629,\n",
            "        -0.02745311,  0.04553752],\n",
            "       [-0.07805956,  0.06038949,  0.08203064, ..., -0.01820625,\n",
            "        -0.00583188, -0.01328713],\n",
            "       [-0.07087789, -0.00442972,  0.01649372, ...,  0.05283497,\n",
            "         0.05438674, -0.02604757]], dtype=float32), array([ 0.03113467,  0.03307803,  0.0151818 , -0.0279049 , -0.02118912,\n",
            "        0.02292916, -0.00432442, -0.00127798, -0.03604849,  0.00362935],\n",
            "      dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the model into .h5 "
      ],
      "metadata": {
        "id": "H5fXKLt92ppK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkbUOpsvoapv",
        "outputId": "79b0e821-967c-425d-f823-3a9b91d774e3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wt = open('weights.csv', 'w')\n",
        "bs = open('biases.csv', 'w')\n",
        "for idx,i in enumerate(model.layers):\n",
        "  if(isinstance(i, Conv2D) or isinstance(i, Dense)):\n",
        "    weights = i.get_weights()[0]\n",
        "    biases = i.get_weights()[1]\n",
        "    weights = weights.flatten()\n",
        "    biases = biases.flatten()\n",
        "    print(weights.shape, biases.shape)\n",
        "    wt.write(','.join(map(str,weights.tolist()))+\"\\n\")\n",
        "    bs.write(','.join(map(str,biases.tolist()))+\"\\n\")\n",
        "    np.savetxt(\"weight\" + str(idx)+\".csv\" , weights , fmt='%s', delimiter=',')\n",
        "    np.savetxt(\"bias\" + str(idx) +\".csv\" , biases , fmt='%s', delimiter=',')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvX9364Xo7nM",
        "outputId": "823b76ca-d730-423b-eed4-ea0f1d1aa5e5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(576,) (64,)\n",
            "(36864,) (64,)\n",
            "(16000,) (10,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aJf01PafrK3B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}